services:
  traefik:
    image: traefik:v3.5
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--entrypoints.web.address=:8081"
      - "--providers.docker.exposedbydefault=false"
      # - "--accesslog=true"
      # - "--log.level=DEBUG"
    ports:
      - "8081:8081"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@localhost:9093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  es:
   image: docker.elastic.co/elasticsearch/elasticsearch:8.17.4
   environment:
     node.name: es
     cluster.name: es-docker-cluster
     ES_JAVA_OPTS: -Xms512m -Xmx512m
     xpack.security.enabled: false
     discovery.type: single-node
   healthcheck:
     test: [ "CMD-SHELL", "curl -fsS http://localhost:9200/_cluster/health | grep -vq '\"status\":\"red\"'" ]
     interval: 15s
     timeout: 10s
     retries: 5
     start_period: 30s

  kibana:
   image: docker.elastic.co/kibana/kibana:8.17.4
   environment:
     ELASTICSEARCH_HOSTS: http://es:9200
   ports:
     - "5601:5601"

  logstash:
    image: logstash:9.0.2
    depends_on:
      init-services:
        condition: service_completed_successfully
    volumes:
      - ./logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml
      - ./logstash/pipeline/health_checks.conf:/usr/share/logstash/pipeline/health_checks.conf
      - ./logstash/pipeline/logs.conf:/usr/share/logstash/pipeline/logs.conf
      - ./logstash/pipeline/servers.conf:/usr/share/logstash/pipeline/servers.conf
    environment:
      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"

  redis:
    image: redis:latest
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
      interval: 10s
      timeout: 5s
      retries: 5

  init-services:
    image: confluentinc/cp-kafka:7.2.15
    container_name: init-services
    depends_on:
      kafka:
        condition: service_healthy
      source-connector:
        condition: service_healthy
      es:
        condition: service_healthy
    volumes:
      - ./setup:/setup
    command: [ "bash", "/setup/setup.sh" ]

  pg-server-service:
    image: postgres:17.4
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U admin" ]
      interval: 15s
      timeout: 5s
      retries: 5
    volumes:
      - ./init_server_service.sql:/docker-entrypoint-initdb.d/init.sql

  pg-scheduler:
    image: postgres:17.4
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U admin" ]
      interval: 15s
      timeout: 5s
      retries: 5
    volumes:
      - ./init_scheduler.sql:/docker-entrypoint-initdb.d/init.sql

  pg-auth-service:
    image: postgres:17.4
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U admin" ]
      interval: 15s
      timeout: 5s
      retries: 5
    volumes:
      - ./init_auth_service.sql:/docker-entrypoint-initdb.d/init.sql

  source-connector:
      image: debezium/connect:3.0.0.Final
      depends_on:
        kafka:
          condition: service_healthy
        pg-server-service:
          condition: service_healthy
      environment:
        GROUP_ID: 1
        CONFIG_STORAGE_TOPIC: source-connector-configs
        OFFSET_STORAGE_TOPIC: source-connector-offsets
        STATUS_STORAGE_TOPIC: source-connector-status
        BOOTSTRAP_SERVERS: kafka:9092
        KEY_CONVERTER_SCHEMAS_ENABLE: "false"
        VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
        CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_REST_ADVERTISED_HOST_NAME: source-connector
      healthcheck:
        test: [ "CMD", "curl", "--fail", "--silent", "--output", "/dev/null", "http://localhost:8083/connectors" ]
        interval: 15s
        timeout: 10s
        retries: 5
        start_period: 30s

  swagger-ui:
    image: swaggerapi/swagger-ui
    volumes:
      - ../docs/api.yml:/spec/openapi.yml
    environment:
      SWAGGER_JSON: /spec/openapi.yml
      BASE_URL: /docs
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.swagger-router.rule=PathPrefix(`/docs`)"
      - "traefik.http.services.swagger-service.loadbalancer.server.port=8080"

  auth-service:
    build:
      context: ../
      dockerfile: ./build/auth-service/Dockerfile
    environment:
      POSTGRES_HOST: pg-auth-service
      POSTGRES_PORT: 5432
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
      POSTGRES_DB: auth

      SERVER_PORT: 8080
      LOG_LEVEL: info
      USER_SESSION_TTL: 720h

      JWT_SECRET_KEY: supersecretkey1233456
      JWT_ACCESS_TOKEN_TTL: 120m
      JWT_REFRESH_TOKEN_TTL: 168h

      REDIS_HOST: redis
      REDIS_PORT: 6379

    volumes:
      - app-logs:/app/log
    depends_on:
      pg-auth-service:
        condition: service_healthy
      redis:
        condition: service_healthy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.auth-router.rule=PathPrefix(`/auth`)"
      - "traefik.http.routers.scope-router.rule=PathPrefix(`/scopes`)"
      - "traefik.http.routers.role-router.rule=PathPrefix(`/roles`)"
      - "traefik.http.routers.user-router.rule=PathPrefix(`/users`)"
      - "traefik.http.middlewares.custom-auth.forwardauth.address=http://auth-service:8080/auth/verify"
      - "traefik.http.middlewares.custom-auth.forwardauth.authResponseHeaders=X-User-Id,X-User-Scopes"
      - "traefik.http.services.auth-service.loadbalancer.server.port=8080"

  server-service:
    build:
      context: ../
      dockerfile: ./build/server-service/Dockerfile
    environment:
      POSTGRES_HOST: pg-server-service
      POSTGRES_PORT: 5432
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
      POSTGRES_DB: servers

      ELASTICSEARCH_ADDRESSES: http://es:9200

      SERVER_PORT: 8080
      LOG_LEVEL: info

      MAIL_EMAIL: tringuyenhn03@gmail.com
      MAIL_PASSWORD: zxda bgjn aqhb yppb
      MAIL_HOST: smtp.gmail.com
      MAIL_PORT: 587
      MAIL_ADMIN_EMAIL: tringuyenhn03@gmail.com
    volumes:
      - app-logs:/app/log
    depends_on:
      init-services:
        condition: service_completed_successfully
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.server-router.rule=PathPrefix(`/servers`)"
      - "traefik.http.routers.server-router.middlewares=custom-auth"
      - "traefik.http.services.server-service.loadbalancer.server.port=8080"

  scheduler:
    build:
      context: ../
      dockerfile: ./build/scheduler/Dockerfile
    environment:
      POSTGRES_HOST: pg-scheduler
      POSTGRES_PORT: 5432
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
      POSTGRES_DB: scheduler

      LOG_LEVEL: info

      KAFKA_BROKERS: kafka:9092
      KAFKA_CONSUMER_TOPIC: server-svc.public.servers
      KAFKA_PRODUCER_TOPIC: server_checks_events
      KAFKA_CONSUMER_GROUP_ID: scheduler-consumers
      KAFKA_CONSUMER_CNT: 3
    volumes:
      - app-logs:/app/log
    depends_on:
      init-services:
        condition: service_completed_successfully
      pg-scheduler:
        condition: service_healthy

  health-checker:
    build:
      context: ../
      dockerfile: ./build/health-checker/Dockerfile
    environment:
      LOG_LEVEL: info
      MAX_RETRIES: 5
      INITIAL_BACKOFF: 1s
      REQUEST_TIMEOUT: 1s

      KAFKA_BROKERS: kafka:9092
      KAFKA_CONSUMER_TOPIC: server_checks_events
      KAFKA_PRODUCER_TOPIC: health_checks_events
      KAFKA_CONSUMER_GROUP_ID: health-checkers-consumers
      KAFKA_CONSUMER_CNT: 3
    volumes:
      - app-logs:/app/log
    depends_on:
      init-services:
        condition: service_completed_successfully

  health-check-consumer:
    build:
      context: ../
      dockerfile: ./build/health-check-consumer/Dockerfile
    environment:
      LOG_LEVEL: info

      POSTGRES_HOST: pg-server-service
      POSTGRES_PORT: 5432
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: 123456
      POSTGRES_DB: servers

      KAFKA_BROKERS: kafka:9092
      KAFKA_CONSUMER_TOPIC: health_checks_events
      KAFKA_CONSUMER_GROUP_ID: health-checks-consumers
      KAFKA_CONSUMER_CNT: 3
    volumes:
      - app-logs:/app/log
    depends_on:
      init-services:
        condition: service_completed_successfully

  filebeat:
    image: elastic/filebeat:9.0.0
    user: root
    command: >
      sh -c "
        chown root:root /usr/share/filebeat/filebeat.yml;
        chmod go-w /usr/share/filebeat/filebeat.yml;
        /usr/local/bin/docker-entrypoint -e;
      "
    volumes:
      - app-logs:/var/log/app
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml

volumes:
  app-logs: